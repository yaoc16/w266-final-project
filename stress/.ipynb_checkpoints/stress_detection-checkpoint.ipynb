{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ad0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Stress Detection ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a647087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import tqdm\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b080adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7141b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>...</th>\n",
       "      <th>lex_dal_min_pleasantness</th>\n",
       "      <th>lex_dal_min_activation</th>\n",
       "      <th>lex_dal_min_imagery</th>\n",
       "      <th>lex_dal_avg_activation</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>33181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77000</td>\n",
       "      <td>1.52211</td>\n",
       "      <td>1.89556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>3.253573</td>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>2606</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "      <td>4</td>\n",
       "      <td>9.429737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.69586</td>\n",
       "      <td>1.62045</td>\n",
       "      <td>1.88919</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2</td>\n",
       "      <td>8.828316</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit post_id sentence_range  \\\n",
       "0        ptsd  8601tu       (15, 20)   \n",
       "1  assistance  8lbrx9         (0, 5)   \n",
       "\n",
       "                                                text     id  label  \\\n",
       "0  He said he had not felt that way before, sugge...  33181      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...   2606      0   \n",
       "\n",
       "   confidence  social_timestamp  social_karma  syntax_ari  ...  \\\n",
       "0         0.8        1521614353             5    1.806818  ...   \n",
       "1         1.0        1527009817             4    9.429737  ...   \n",
       "\n",
       "   lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
       "0                     1.000                   1.125                  1.0   \n",
       "1                     1.125                   1.000                  1.0   \n",
       "\n",
       "   lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
       "0                 1.77000              1.52211                   1.89556   \n",
       "1                 1.69586              1.62045                   1.88919   \n",
       "\n",
       "   social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \n",
       "0                 0.86                    1         3.253573  -0.002742  \n",
       "1                 0.65                    2         8.828316   0.292857  \n",
       "\n",
       "[2 rows x 116 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creating a function\n",
    "def func_tokenizer(tokenizer_name, docs):\n",
    "    features = []\n",
    "    for doc in tqdm.tqdm(docs, desc = 'converting documents to features'):\n",
    "        tokens = tokenizer_name.tokenize(doc)\n",
    "        ids = tokenizer_name.convert_tokens_to_ids(tokens)\n",
    "        features.append(ids)\n",
    "    return features\n",
    "print(\"The function is created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "X,y = train[['text', 'lex_liwc_Tone', 'lex_liwc_negemo', 'lex_liwc_Clout','lex_liwc_i', 'sentiment' ]], train['label']\n",
    "bert_features = func_tokenizer(bert_tokenizer, X['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
